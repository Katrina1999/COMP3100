Stage 2
Katrina David (45308748)	     Sakura Mukhopadhyay (45435073)  	       Trideep Lal Das (45532125)
Group 8 (Thursday 4pm-6pm)

Introduction
Priority Scheduling is the task of scheduling jobs based on a scale of importance. 
This importance is based on the submission time in which a particular job is sent to the scheduler. 
Stage 2 of Group 8’s Priority Job Scheduler for Distributed Systems involves understanding and implementing three simple scheduling algorithms that are based on memory allocation policies.
The three scheduling algorithms implemented in Group 8’s priority scheduler are First-Fit, Best-Fit and Worst-Fit algorithms schemes. 
Stage 2 of this project also includes producing a simulation log generated by the server-side simulator and is based on simulation statistics that are presented to the team members at the end of simulation. 
Group 8’s algorithm design document features the design considerations and preliminaries for data structures used in Group 8’s Priority Scheduler as well as detailed algorithm descriptions for each of the three simple scheduling algorithms; First-Fit, Best-Fit and Worst-Fit Algorithms. 

Design	consideration

Preliminaries

First Fit Algorithm	description  - implemented by Trideep Lal Das 
The First-Fit Algorithm is an algorithm that scans through the computer memory from beginning to the end. 
It finds the first partition of memory large enough to accommodate the job given, then allocates the job to that memory partition. 
After this, there are two conditions we can take a look at; firstly being checking for leftover space which then becomes a separate free space and secondly, when the job size exceeds the biggest free space in terms of memory, it returns an error.

When looking at the FF algorithm, it is key to note that there are a few advantages and disadvantages to implementing this algorithm. 
The most apparent of the advantages is that compared to all other algorithms, FF is the fastest algorithm as it essentially just needs to find the nearest memory and then allocate the job to that partition. 
Although a point of contention for some, the biggest disadvantage to this algorithm is the wastefulness in terms of memory exhibited by this algorithm. 
The algorithm does not account for the size of the job compared to the size of the partition, leaving unused partitions of memory which is generally a rather small amount. As such, memory space is wasted, and jobs would frequently have to wait for another job to be completed to then be allocated to the memory.

Best Fit Algorithm	description - implemented by Katrina David 
The Best-Fit Algorithm is an algorithm that deals with allocating the smallest available free partition that meets the requirement of the requesting process. 
The algorithm when implemented in a job scheduler for distributed systems works by undertaking two key steps; a search for bR1 which is the local best fit in region R1 followed by a search of bR2 which is the best fit in region R2. 
After conducting a search through both regions, the best-fit algorithm checks the smallest and most appropriate block for the job and will return the overall best fit for the given job if it exists. 

Thoroughly understanding the Best-Fit algorithm also involves analysing the advantages and disadvantages that affect the performance of the algorithm. 
The primary advantage of this algorithm in comparison to the first-fit and worst-fit algorithms is that it is fast and successful memory utilisation as it searches the smallest free partition first available. 
However, this algorithm also has a disadvantage, namely that it is slowest of them all and may have the tendency to fill up memory partitions with tiny purposeless holes. 
  
Worst Fit Algorithm	description - implemented by Sakura Mukhopadhyay
The worst-fit algorithm looks for memory space that is free and has enough storage space for the requested  task. 
The algorithm selects the largest free memory space that is available and that has more memory space than the desired task’s required memory space. 
It then stores the requested information directly into this vacant memory space. 
By implementing this algorithm, we observe the processor allocates any memory block that is vacant to the ongoing process. 
This leads to an increase in the probability of memory being wasted and hence is called the worst-fit algorithm. 
When the allocated tasks are of medium sized memory space tasks, the worst-fit algorithm is ideal and works efficiently. 
However, they break up the potential of using the largest free memory block for further tasks as these large memory spaces cannot be reallocated and end up being wasted and unused. 
It also causes external fragmentation and other algorithm schemes are usually higher choices in implementing into the distributed system. 

      
References    
